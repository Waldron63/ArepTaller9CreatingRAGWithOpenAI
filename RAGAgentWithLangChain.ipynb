{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the OpenAI integration\n",
    "%pip install -U langchain-openai\n",
    "\n",
    "# Installing the Anthropic integration\n",
    "%pip install -U langchain-anthropic\n",
    "%pip install -U langchain langchain-text-splitters langchain-community bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248eeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%export LANGSMITH_TRACING=\"true\"\n",
    "%export LANGSMITH_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ae5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"langchain-openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb550fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"langchain-core\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb786951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_url(url: str) -> str:\n",
    "    \"\"\"Fetch text content from a URL\"\"\"\n",
    "    response = requests.get(url, timeout=10.0)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "system_prompt = \"\"\"\\\n",
    "Use fetch_url when you need to fetch information from a web-page; quote relevant snippets.\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    tools=[fetch_url], # A tool for retrieval\n",
    "    system_prompt=system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2034929",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str, section: Literal[\"beginning\", \"middle\", \"end\"]):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49143ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition?\"\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
